{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math,os,random\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MolFromSmiles,MolToSmiles\n",
    "import argparse\n",
    "from rdkit.Chem import Draw,AllChem,DataStructs,rdFMCS\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "\n",
    "from mol_generation import *\n",
    "from utils import Penalized_logp, Similarity, DockingScore, prop_all\n",
    "from utils import prepare_ligand, prepare_rep, calculate_center, mol2sdf\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "\n",
    "import re\n",
    "import csv\n",
    "from itertools import islice\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range(atoms):\n",
    "        mol.GetAtomWithIdx(idx).SetProp('molAtomMapNumber', str(mol.GetAtomWithIdx(idx).GetIdx()))\n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "seed = 2\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "with open(\"datafinal_0105.pkl\", 'rb') as f:\n",
    "    # input_x = pickle.load(f)\n",
    "    pickle.load(f)\n",
    "    input_y = pickle.load(f)\n",
    "    all_mol = pickle.load(f)\n",
    "    all_index = pickle.load(f)\n",
    "    all_freq_list = pickle.load(f)\n",
    "\n",
    "print(len(all_mol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_list = []\n",
    "for i in range(len(all_freq_list)):\n",
    "    # 如果all_freq_list中的元素有10-12，就将其索引加入del_list\n",
    "    if 9 in all_freq_list[i] or 10 in all_freq_list[i] or 11 in all_freq_list[i] or 12 in all_freq_list[i]:\n",
    "        del_list.append(i)\n",
    "\n",
    "# 删除all_mol, all_index, all_freq_list中索引为del_list的元素\n",
    "all_mol = [all_mol[i] for i in range(len(all_mol)) if i not in del_list]\n",
    "all_index = [all_index[i] for i in range(len(all_index)) if i not in del_list]\n",
    "all_freq_list = [all_freq_list[i] for i in range(len(all_freq_list)) if i not in del_list]\n",
    "input_y = [input_y[i] for i in range(len(input_y)) if i not in del_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(input_x))\n",
    "print(len(input_y))\n",
    "print(len(all_mol))\n",
    "print(len(all_index))\n",
    "print(len(all_freq_list))\n",
    "\n",
    "i = 22457\n",
    "# print(input_x[i].shape)\n",
    "print(input_y[i])\n",
    "print(all_index[i])\n",
    "print(all_freq_list[i])\n",
    "all_mol[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把所有分子的iso替换为该原子位置的freq\n",
    "for i in range(len(all_mol)):\n",
    "    cur_mol = all_mol[i]\n",
    "    cur_freq_list = all_freq_list[i]\n",
    "    atoms = cur_mol.GetNumAtoms()\n",
    "    for j in range(atoms):  \n",
    "        cur_mol.GetAtomWithIdx(j).SetIsotope(cur_freq_list[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_index 里的元素转为one-hot向量\n",
    "new_input_y_onehot = []\n",
    "for i in range(len(all_index)):\n",
    "    cur_y = all_index[i]\n",
    "    cur_y_onehot = [0] * len(all_freq_list[i])\n",
    "    cur_y_onehot[cur_y] = 1\n",
    "    new_input_y_onehot.append(cur_y_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model-new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_data(X, y, ratio=0.8):\n",
    "    n = len(X)\n",
    "    \n",
    "    permutation = np.random.choice(n, n, replace=False)\n",
    "\n",
    "    train_size = int(np.round(ratio * n))\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train = [X[i] for i in permutation[:train_size]]\n",
    "    y_train = [y[i] for i in permutation[:train_size]]\n",
    "\n",
    "    X_test = [X[i] for i in permutation[train_size:]]\n",
    "    y_test = [y[i] for i in permutation[train_size:]]\n",
    "\n",
    "    return (X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_data_val(X, y, ratio=0.8, ratio2=0.9):\n",
    "    n = len(X)\n",
    "    \n",
    "    permutation = np.random.choice(n, n, replace=False)\n",
    "\n",
    "    train_size = int(np.round(ratio * n))\n",
    "    val_size = int(np.round(ratio2 * n))\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train = [X[i] for i in permutation[:train_size]]\n",
    "    y_train = [y[i] for i in permutation[:train_size]]\n",
    "\n",
    "    X_test = [X[i] for i in permutation[train_size:val_size]]\n",
    "    y_test = [y[i] for i in permutation[train_size:val_size]]\n",
    "\n",
    "    X_val = [X[i] for i in permutation[val_size:]]\n",
    "    y_val = [y[i] for i in permutation[val_size:]]\n",
    "\n",
    "    return (X_train,X_test,X_val,y_train,y_test,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(epoch, training_losses, training_accuracies, validation_losses, validation_accuracies, testing_losses, testing_accuracies):\n",
    "    epochs = np.arange(1, len(training_losses)+1)\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, training_losses, label='Training Loss')\n",
    "    plt.plot(epochs, validation_losses, label='Validation Loss')\n",
    "    plt.plot(epochs, testing_losses, label='Testing Loss')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, training_accuracies, label='Training Accuracy')\n",
    "    plt.plot(epochs, validation_accuracies, label='Validation Accuracy')\n",
    "    plt.plot(epochs, testing_accuracies, label='Testing Accuracy')\n",
    "    plt.title('Accuracy Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_input_size = 119\n",
    "atom_hidden_size = 300\n",
    "atom_output_size = 1\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model1224 import *\n",
    "from mol_generation1224 import *\n",
    "\n",
    "class AtomPredictionNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=2):\n",
    "        super(AtomPredictionNetwork, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_size, hidden_size))\n",
    "        layers.append(nn.ReLU())\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            # layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.Dropout(p = 0.2))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(hidden_size, 1))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "class MolecularPredictionNetwork(nn.Module):\n",
    "    def __init__(self, atom_input_size, atom_hidden_size):\n",
    "        super(MolecularPredictionNetwork, self).__init__()\n",
    "        self.atom_network = AtomPredictionNetwork(atom_input_size, atom_hidden_size)\n",
    "        self.gnn = GenerativeModel2(num_layer=5, emb_dim=300, gnn_type = \"gin\")\n",
    "        # self.fc = nn.Linear(atom_hidden_size, 1)\n",
    "    def forward(self, mol_list):\n",
    "        molecule_scores_list = []\n",
    "        X_list = []\n",
    "        for i in range(len(mol_list)):\n",
    "            cur_mol = mol_list[i]\n",
    "            graph_feature = new_mol_to_graph_data(cur_mol)\n",
    "            X = self.gnn(graph_feature)\n",
    "            X_list.append(X)\n",
    "\n",
    "        for x in X_list:\n",
    "            atom_outputs = torch.zeros(len(x))\n",
    "            for i in range((len(x))):\n",
    "                atom_outputs[i] = self.atom_network(x[i])\n",
    "            molecule_scores_list.append(atom_outputs)\n",
    "        return molecule_scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MolecularPredictionNetwork(atom_input_size, atom_hidden_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    acc_list = []\n",
    "    for i in range(len(y_pred)):\n",
    "        # top_pred = y_pred[i].argmax(0, keepdim=True)\n",
    "        # 找到y_pred中top5的index\n",
    "        top_pred = y_pred[i].argsort(descending=True)[:5]\n",
    "        top_true = y[i]\n",
    "        if top_true.argmax(0, keepdim=True) in top_pred:\n",
    "            acc_list.append(1)\n",
    "        else:\n",
    "            acc_list.append(0)\n",
    "    return sum(acc_list) / len(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(y_pred, y):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    batch_loss = []\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pre = y_pred[i].float()\n",
    "        y_tru = y[i].float()\n",
    "        loss = criterion(y_pre, y_tru)\n",
    "        batch_loss.append(loss)\n",
    "    return sum(batch_loss) / len(batch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star = 0\n",
    "end = -1\n",
    "\n",
    "inputs = all_mol[star:end]\n",
    "labels = [torch.tensor(one_hot) for one_hot in new_input_y_onehot[star:end]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = get_split_data_val(inputs, labels, 0.8, 0.9)\n",
    "print(len(X_train), len(X_test) ,len(X_val), len(y_train), len(y_test), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CLSmodel_val(X_train, y_train, X_val, y_val, X_test, y_test, num_epoch=500, batch_size=128, lambda_reg=0.01, learning_rate=0.001):\n",
    "    num = len(X_train)\n",
    "    batchsize = batch_size\n",
    "    train_bs = int(math.ceil(num / batchsize))\n",
    "    lambda_reg = lambda_reg\n",
    "\n",
    "    mlp = MolecularPredictionNetwork(atom_input_size, atom_hidden_size)\n",
    "    optimizer = optim.Adam(mlp.parameters(), lr=learning_rate)\n",
    "    mlp.train()\n",
    "\n",
    "    training_losses = []\n",
    "    training_accuracies = []\n",
    "    validation_losses = []  \n",
    "    validation_accuracies = []  \n",
    "    testing_losses = []  \n",
    "    testing_accuracies = [] \n",
    "    batch_training_losses = []\n",
    "\n",
    "    maxacc = 1e10\n",
    "    iepoch = 0\n",
    "    for i in range(num_epoch):\n",
    "        print(\"---------------------------------- Epoch --------------------------------------\", i)\n",
    "        print(\"************** Training **************\")\n",
    "        epoch_training_loss = 0.0\n",
    "        epoch_training_accuracy = 0.0\n",
    "\n",
    "        for k in range(train_bs):\n",
    "            mlp.zero_grad()\n",
    "            batch = X_train[k * batchsize:(k + 1) * batchsize]\n",
    "            target = y_train[k * batchsize:(k + 1) * batchsize]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = mlp.forward(batch)\n",
    "            loss = calculate_loss(pred, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            acc = calculate_accuracy(pred, target)\n",
    "\n",
    "            epoch_training_loss += loss.item()\n",
    "            epoch_training_accuracy += acc\n",
    "            batch_training_losses.append(loss.item())\n",
    "\n",
    "            # 打印每个batch的pred和true\n",
    "            batch_pred = []\n",
    "            batch_true = []\n",
    "            for j in range(len(pred)):\n",
    "                top_pred = pred[j].argsort(descending=True)[:5]\n",
    "                top_true = target[j]\n",
    "                batch_pred.append(top_pred.tolist())\n",
    "                batch_true.append(top_true)\n",
    "                \n",
    "        # print(\"training batch_pred\", batch_pred)\n",
    "        # print(\"training batch_true\", batch_true)\n",
    "        epoch_training_loss /= train_bs\n",
    "        epoch_training_accuracy /= train_bs\n",
    "        training_losses.append(epoch_training_loss)\n",
    "        training_accuracies.append(epoch_training_accuracy)\n",
    "        print(\"epoch: {}, loss: {}, acc: {}\".format(i, epoch_training_loss, epoch_training_accuracy))\n",
    "\n",
    "        if X_test is not None:\n",
    "            print(\"************** Testing **************\")\n",
    "            mlp.eval()\n",
    "            test_accs = []\n",
    "            test_losses = []\n",
    "            test_bs = int(math.ceil(len(X_test) / batchsize))\n",
    "            epoch_testing_loss = 0.0\n",
    "            epoch_testing_accuracy = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for j in range(test_bs):\n",
    "                    batch = X_test[j * batchsize:(j + 1) * batchsize]\n",
    "                    target = y_test[j * batchsize:(j + 1) * batchsize]\n",
    "\n",
    "                    pred = mlp.forward(batch)\n",
    "                    loss = calculate_loss(pred, target)\n",
    "                    test_losses.append(loss.item())\n",
    "                    acc = calculate_accuracy(pred, target)\n",
    "                    test_accs.append(acc)\n",
    "\n",
    "                    epoch_testing_loss += loss.item()\n",
    "                    epoch_testing_accuracy += acc\n",
    "\n",
    "                    batch_pred = []\n",
    "                    batch_true = []\n",
    "                    for j in range(len(pred)):\n",
    "                        top_pred = pred[j].argsort(descending=True)[:5]\n",
    "                        top_true = target[j]\n",
    "                        batch_pred.append(top_pred.tolist())\n",
    "                        batch_true.append(top_true)\n",
    "\n",
    "            # print(\"testing batch_pred\", batch_pred)\n",
    "            # print(\"testing batch_true\", batch_true)\n",
    "            avg_test_loss = np.mean(test_losses)\n",
    "            avg_test_acc = np.mean(test_accs)\n",
    "            testing_losses.append(avg_test_loss)\n",
    "            testing_accuracies.append(avg_test_acc)\n",
    "            print(\"Testing loss: {}, acc: {}\".format(avg_test_loss, avg_test_acc))\n",
    "\n",
    "        if X_val is not None:\n",
    "            print(\"************** Validation **************\")\n",
    "            mlp.eval()\n",
    "            val_accs = []\n",
    "            val_losses = []\n",
    "            val_bs = int(math.ceil(len(X_val) / batchsize))\n",
    "            epoch_validation_loss = 0.0\n",
    "            epoch_validation_accuracy = 0.0\n",
    "\n",
    "            for j in range(val_bs):\n",
    "                batch = X_val[j * batchsize:(j + 1) * batchsize]\n",
    "                target = y_val[j * batchsize:(j + 1) * batchsize]\n",
    "\n",
    "                pred = mlp.forward(batch)\n",
    "                loss = calculate_loss(pred, target)\n",
    "                val_losses.append(loss.item())\n",
    "                acc = calculate_accuracy(pred, target)\n",
    "                val_accs.append(acc)\n",
    "\n",
    "                epoch_validation_loss += loss.item()\n",
    "                epoch_validation_accuracy += acc\n",
    "\n",
    "            avg_val_loss = np.mean(val_losses)\n",
    "            avg_val_acc = np.mean(val_accs)\n",
    "            validation_losses.append(avg_val_loss)\n",
    "            validation_accuracies.append(avg_val_acc)\n",
    "\n",
    "            print(\"Validation loss: {}, acc: {}\".format(avg_val_loss, avg_val_acc))\n",
    "\n",
    "            # early-stopping based on validation loss\n",
    "            if avg_val_loss < maxacc:\n",
    "                maxacc = avg_val_loss\n",
    "                iepoch = i\n",
    "            if i - iepoch > 5:\n",
    "                break\n",
    "\n",
    "    return mlp, iepoch, training_losses, training_accuracies, validation_losses, validation_accuracies, testing_losses, testing_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp , kepoch, training_losses, training_accuracies, validation_losses, validation_accuracies, testing_losses, testing_accuracies = \\\n",
    "get_CLSmodel_val(X_train, y_train, X_val, y_val, X_test, y_test, 100, 128, 0.01, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(kepoch, training_losses, training_accuracies, validation_losses, validation_accuracies, testing_losses, testing_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mol , X_test_mol, X_val_mol, y_train_idx , y_test_idx, y_val_index = get_split_data_val(all_mol[star:end], all_index[star:end], 0.8, 0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
